{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.engine import InputSpec\n",
    "from keras.layers import Recurrent, initializations, activations, regularizers, time_distributed_dense, SimpleRNN, GRU, \\\n",
    "    LSTM\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "\n",
    "def identity_loss(y_true, y_pred):\n",
    "    return K.mean(y_pred - 0 * y_true)\n",
    "\n",
    "class CARA(GRU):\n",
    "    def __init__(self, output_dim,\n",
    "                 init='glorot_uniform', inner_init='orthogonal',\n",
    "                 activation='tanh', inner_activation='hard_sigmoid',\n",
    "                 W_regularizer=None, U_regularizer=None, b_regularizer=None,\n",
    "                 dropout_W=0., dropout_U=0., **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.init = initializations.get(init)\n",
    "        self.inner_init = initializations.get(inner_init)\n",
    "        self.activation = activations.get(activation)\n",
    "        self.inner_activation = activations.get(inner_activation)\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.U_regularizer = regularizers.get(U_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "        self.dropout_W = dropout_W\n",
    "        self.dropout_U = dropout_U\n",
    "\n",
    "        if self.dropout_W or self.dropout_U:\n",
    "            self.uses_learning_phase = True\n",
    "        super(GRU, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(shape=input_shape)]\n",
    "        self.input_dim = 10\n",
    "\n",
    "        if self.stateful:\n",
    "            self.reset_states()\n",
    "        else:\n",
    "            # initial states: all-zero tensor of shape (output_dim)\n",
    "            self.states = [None]\n",
    "\n",
    "        self.W_z = self.add_weight((self.input_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_W_z'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.U_z = self.add_weight((self.output_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_U_z'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.b_z = self.add_weight((self.output_dim,),\n",
    "                                   initializer='zero',\n",
    "                                   name='{}_b_z'.format(self.name),\n",
    "                                   regularizer=self.b_regularizer)\n",
    "        self.W_r = self.add_weight((self.input_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_W_r'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.U_r = self.add_weight((self.output_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_U_r'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.b_r = self.add_weight((self.output_dim,),\n",
    "                                   initializer='zero',\n",
    "                                   name='{}_b_r'.format(self.name),\n",
    "                                   regularizer=self.b_regularizer)\n",
    "        self.W_h = self.add_weight((self.input_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_W_h'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.U_h = self.add_weight((self.output_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_U_h'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.b_h = self.add_weight((self.output_dim,),\n",
    "                                   initializer='zero',\n",
    "                                   name='{}_b_h'.format(self.name),\n",
    "                                   regularizer=self.b_regularizer)\n",
    "\n",
    "        self.A_h = self.add_weight((self.output_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_A_h'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.A_u = self.add_weight((self.output_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_A_u'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "\n",
    "        self.b_a_h = self.add_weight((self.output_dim,),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b_a_h'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer)\n",
    "        self.b_a_u = self.add_weight((self.output_dim,),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b_a_u'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer)\n",
    "\n",
    "\n",
    "        self.W_t = self.add_weight((self.input_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_W_t'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.U_t = self.add_weight((1, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_U_t'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.b_t = self.add_weight((self.output_dim,),\n",
    "                                   initializer='zero',\n",
    "                                   name='{}_b_t'.format(self.name),\n",
    "                                   regularizer=self.b_regularizer)\n",
    "\n",
    "        self.W_g = self.add_weight((self.input_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_W_g'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.U_g = self.add_weight((1, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_U_g'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.b_g = self.add_weight((self.output_dim,),\n",
    "                                   initializer='zero',\n",
    "                                   name='{}_b_g'.format(self.name),\n",
    "                                   regularizer=self.b_regularizer)\n",
    "\n",
    "\n",
    "\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "\n",
    "    def preprocess_input(self, x):\n",
    "        return x\n",
    "\n",
    "    def step(self, x, states):\n",
    "        h_tm1 = states[0]  # previous memory\n",
    "        B_U = states[1]  # dropout matrices for recurrent units\n",
    "        B_W = states[2]\n",
    "\n",
    "        u = x[:, self.output_dim: 2 * self.output_dim]\n",
    "        t = x[:, 2 * self.output_dim: (2 * self.output_dim) + 1]\n",
    "        g = x[:, (2 * self.output_dim) + 1:]\n",
    "        x = x[:, :self.output_dim]\n",
    "        \n",
    "        t = self.inner_activation(K.dot(t, self.U_t))\n",
    "        g = self.inner_activation(K.dot(g, self.U_g))\n",
    "#       Time-based gate\n",
    "        T = self.inner_activation(K.dot(x, self.W_t) + t + self.b_t)\n",
    "#       Geo-based gate\n",
    "        G = self.inner_activation(K.dot(x, self.W_g) + g + self.b_g)\n",
    "\n",
    "#       Contextual Attention Gate\n",
    "        a = self.inner_activation(\n",
    "            K.dot(h_tm1, self.A_h) + K.dot(u, self.A_u) + self.b_a_h + self.b_a_u)\n",
    "\n",
    "        x_z = K.dot(x, self.W_z) + self.b_z\n",
    "        x_r = K.dot(x, self.W_r) + self.b_r\n",
    "        x_h = K.dot(x, self.W_h) + self.b_h\n",
    "\n",
    "        u_z_ = K.dot((1 - a) * u, self.W_z) + self.b_z\n",
    "        u_r_ = K.dot((1 - a) * u, self.W_r) + self.b_r\n",
    "        u_h_ = K.dot((1 - a) * u, self.W_h) + self.b_h\n",
    "\n",
    "        u_z = K.dot(a * u, self.W_z) + self.b_z\n",
    "        u_r = K.dot(a * u, self.W_r) + self.b_r\n",
    "        u_h = K.dot(a * u, self.W_h) + self.b_h\n",
    "\n",
    "#       update gate\n",
    "        z = self.inner_activation(x_z + K.dot(h_tm1, self.U_z) + u_z)\n",
    "#       reset gate\n",
    "        r = self.inner_activation(x_r + K.dot(h_tm1, self.U_r) + u_r)\n",
    "#       hidden state\n",
    "        hh = self.activation(x_h + K.dot(r * T * G * h_tm1, self.U_h) + u_h)\n",
    "\n",
    "        h = z * h_tm1 + (1 - z) * hh\n",
    "        h = (1 + u_z_ + u_r_ + u_h_) * h\n",
    "        return h, [h]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context-Aware Venue Recommendation with pairwise ranking function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding, Input, merge, SimpleRNN, Activation, Dense, Flatten, GlobalAveragePooling1D, GRU, \\\n",
    "    LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import itertools\n",
    "from keras.regularizers import l2\n",
    "\n",
    "def init_normal(shape, name=None):\n",
    "    return initializations.normal(shape, scale=0.01, name=name)\n",
    "\n",
    "def bpr_triplet_loss(X):\n",
    "    positive_item_latent, negative_item_latent = X\n",
    "\n",
    "    reg = 0\n",
    "\n",
    "    loss = 1 - K.log(K.sigmoid(\n",
    "        K.sum(positive_item_latent, axis=-1, keepdims=True) -\n",
    "        K.sum(negative_item_latent, axis=-1, keepdims=True))) - reg\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Context-Aware Venue Recommendation with pairwise ranking function\n",
    "class Recommender():\n",
    "    def __init__(self, num_users, num_items, num_times, latent_dim, maxVenue):\n",
    "\n",
    "        self.maxVenue = maxVenue\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "#       Inputs\n",
    "        self.user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
    "        self.checkins_input = Input(shape=(self.maxVenue,), dtype='int32', name='venue_input')\n",
    "        self.neg_checkins_input = Input(shape=(self.maxVenue,), dtype='int32', name='neg_venue_input')\n",
    "        self.time_input = Input(shape=(self.maxVenue,), dtype='int32', name='time_input')\n",
    "        self.gap_time_input = Input(shape=(self.maxVenue, 1,), dtype='float32', name='time_interval_input')\n",
    "        \n",
    "        self.u_embedding = Embedding(input_dim=num_users, output_dim=latent_dim, name='user_embedding', \n",
    "                                     init=init_normal)\n",
    "        self.v_embedding = Embedding(input_dim=num_items, output_dim=latent_dim, name='venue_embedding',\n",
    "                                     init=init_normal) \n",
    "        self.t_embedding = Embedding(input_dim=num_times, output_dim=latent_dim, name='time_embedding',\n",
    "                                     init=init_normal) \n",
    "\n",
    "\n",
    "#       User latent factor\n",
    "        self.u_latent = Flatten()(self.u_embedding(self.user_input))\n",
    "        self.t_latent = Flatten()(self.t_embedding(self.time_input))\n",
    "       \n",
    "        rnn_input = merge(\n",
    "                [self.v_embedding(self.checkins_input), self.t_embedding(self.time_input), self.gap_time_input],\n",
    "                mode=\"concat\")\n",
    "        neg_rnn_input = merge(\n",
    "                [self.v_embedding(self.neg_checkins_input), self.t_embedding(self.time_input), self.gap_time_input],\n",
    "                mode=\"concat\")\n",
    "\n",
    "\n",
    "#         rnn_input = self.v_embedding(self.checkins_input)\n",
    "#         neg_rnn_input = self.v_embedding(self.neg_checkins_input)\n",
    "        \n",
    "        \n",
    "        self.pos_distance_input = Input(shape=(self.maxVenue, 1,), dtype='float32', name='pos_distance_input')\n",
    "        self.neg_distance_input = Input(shape=(self.maxVenue, 1,), dtype='float32', name='neg_distance_input')\n",
    "        rnn_input = merge([rnn_input, self.pos_distance_input], mode=\"concat\")\n",
    "        neg_rnn_input = merge([neg_rnn_input, self.neg_distance_input], mode=\"concat\")\n",
    "\n",
    "\n",
    "        self.rnn = Sequential()\n",
    "#       latent_dim * 2 + 2 = v_embedding + t_embedding + time_gap + distance\n",
    "\n",
    "        self.rnn.add(\n",
    "                        CARA(latent_dim, input_shape=(self.maxVenue, (self.latent_dim * 2) + 2,), unroll=True))\n",
    "        \n",
    "\n",
    "        self.checkins_emb = self.rnn(rnn_input)\n",
    "        self.neg_checkins_emb = self.rnn(neg_rnn_input)\n",
    "\n",
    "        pred = merge([self.checkins_emb, self.u_latent], mode=\"dot\")\n",
    "        neg_pred = merge([self.neg_checkins_emb, self.u_latent], mode=\"dot\")\n",
    "\n",
    "        \n",
    "        INPUT = [self.user_input, self.time_input, self.gap_time_input, self.pos_distance_input,\n",
    "                 self.neg_distance_input, self.checkins_input,\n",
    "                 self.neg_checkins_input]\n",
    "\n",
    "        loss = merge([pred, neg_pred], mode=bpr_triplet_loss, name='loss', output_shape=(1,))\n",
    "        self.model = Model(input=INPUT, output=loss)\n",
    "        self.model.compile(optimizer=Adam(), loss=identity_loss)\n",
    "        \n",
    "    \n",
    "\n",
    "    def rank(self, uid, hist_venues, hist_times, hist_time_gap, hist_distances):\n",
    "        \n",
    "#         hist_venues = hist_venues + [candidate_venue]\n",
    "#         hist_times = hist_times + [time]\n",
    "#         hist_time_gap = hist_time_gap + [time_gap]\n",
    "#         hist_distances = hist_distances + [distance]\n",
    "\n",
    "        u_latent = self.model.get_layer('user_embedding').get_weights()[0][uid]\n",
    "        v_latent = self.model.get_layer('venue_embedding').get_weights()[0][hist_venues]\n",
    "        t_latent = self.model.get_layer('time_embedding').get_weights()[0][hist_times]\n",
    "        rnn_input = np.concatenate([t_latent, hist_time_gap], axis=-1)\n",
    "        rnn_input = np.concatenate([rnn_input, hist_distances], axis=-1)\n",
    "\n",
    "        rnn_input = np.concatenate([v_latent, rnn_input], axis=-1)\n",
    "\n",
    "        dynamic_latent = self.rnn.predict(rnn_input)\n",
    "\n",
    "        scores = np.dot(dynamic_latent, u_latent)\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Training Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10,), (10, 5), (10, 5, 1), (10, 5, 1), (10, 5, 1), (10, 5), (10, 5)]\n",
      "[(0, array([7, 8, 6, 1, 7, 4, 5, 1, 6, 3])), (1, array([[2, 6, 4, 8, 9],\n",
      "       [1, 9, 7, 8, 9],\n",
      "       [2, 4, 2, 1, 1],\n",
      "       [9, 2, 8, 9, 4],\n",
      "       [7, 5, 1, 1, 8],\n",
      "       [7, 2, 5, 8, 0],\n",
      "       [2, 6, 6, 4, 1],\n",
      "       [7, 1, 3, 5, 1],\n",
      "       [6, 3, 2, 2, 7],\n",
      "       [9, 7, 7, 2, 1]])), (2, array([[[97],\n",
      "        [ 0],\n",
      "        [64],\n",
      "        [67],\n",
      "        [94]],\n",
      "\n",
      "       [[97],\n",
      "        [ 5],\n",
      "        [20],\n",
      "        [82],\n",
      "        [34]],\n",
      "\n",
      "       [[77],\n",
      "        [45],\n",
      "        [ 1],\n",
      "        [63],\n",
      "        [79]],\n",
      "\n",
      "       [[ 4],\n",
      "        [79],\n",
      "        [41],\n",
      "        [19],\n",
      "        [36]],\n",
      "\n",
      "       [[66],\n",
      "        [48],\n",
      "        [42],\n",
      "        [51],\n",
      "        [22]],\n",
      "\n",
      "       [[22],\n",
      "        [73],\n",
      "        [34],\n",
      "        [22],\n",
      "        [73]],\n",
      "\n",
      "       [[85],\n",
      "        [ 2],\n",
      "        [46],\n",
      "        [79],\n",
      "        [ 5]],\n",
      "\n",
      "       [[93],\n",
      "        [66],\n",
      "        [33],\n",
      "        [16],\n",
      "        [77]],\n",
      "\n",
      "       [[46],\n",
      "        [ 5],\n",
      "        [64],\n",
      "        [12],\n",
      "        [94]],\n",
      "\n",
      "       [[45],\n",
      "        [69],\n",
      "        [74],\n",
      "        [83],\n",
      "        [54]]])), (3, array([[[13],\n",
      "        [67],\n",
      "        [50],\n",
      "        [68],\n",
      "        [26]],\n",
      "\n",
      "       [[57],\n",
      "        [44],\n",
      "        [39],\n",
      "        [89],\n",
      "        [50]],\n",
      "\n",
      "       [[74],\n",
      "        [64],\n",
      "        [35],\n",
      "        [87],\n",
      "        [65]],\n",
      "\n",
      "       [[92],\n",
      "        [39],\n",
      "        [82],\n",
      "        [52],\n",
      "        [65]],\n",
      "\n",
      "       [[45],\n",
      "        [62],\n",
      "        [62],\n",
      "        [37],\n",
      "        [29]],\n",
      "\n",
      "       [[57],\n",
      "        [95],\n",
      "        [69],\n",
      "        [92],\n",
      "        [14]],\n",
      "\n",
      "       [[ 4],\n",
      "        [60],\n",
      "        [61],\n",
      "        [17],\n",
      "        [76]],\n",
      "\n",
      "       [[15],\n",
      "        [15],\n",
      "        [78],\n",
      "        [96],\n",
      "        [36]],\n",
      "\n",
      "       [[48],\n",
      "        [67],\n",
      "        [98],\n",
      "        [39],\n",
      "        [ 3]],\n",
      "\n",
      "       [[88],\n",
      "        [19],\n",
      "        [51],\n",
      "        [56],\n",
      "        [85]]])), (4, array([[[52],\n",
      "        [ 0],\n",
      "        [ 9],\n",
      "        [25],\n",
      "        [52]],\n",
      "\n",
      "       [[ 1],\n",
      "        [21],\n",
      "        [98],\n",
      "        [11],\n",
      "        [80]],\n",
      "\n",
      "       [[52],\n",
      "        [64],\n",
      "        [23],\n",
      "        [75],\n",
      "        [25]],\n",
      "\n",
      "       [[21],\n",
      "        [74],\n",
      "        [ 5],\n",
      "        [91],\n",
      "        [75]],\n",
      "\n",
      "       [[20],\n",
      "        [ 0],\n",
      "        [28],\n",
      "        [82],\n",
      "        [43]],\n",
      "\n",
      "       [[ 2],\n",
      "        [46],\n",
      "        [67],\n",
      "        [98],\n",
      "        [16]],\n",
      "\n",
      "       [[62],\n",
      "        [50],\n",
      "        [67],\n",
      "        [97],\n",
      "        [69]],\n",
      "\n",
      "       [[91],\n",
      "        [51],\n",
      "        [98],\n",
      "        [ 1],\n",
      "        [63]],\n",
      "\n",
      "       [[43],\n",
      "        [23],\n",
      "        [31],\n",
      "        [59],\n",
      "        [48]],\n",
      "\n",
      "       [[63],\n",
      "        [93],\n",
      "        [73],\n",
      "        [24],\n",
      "        [ 6]]])), (5, array([[8, 2, 8, 9, 5],\n",
      "       [9, 0, 4, 7, 0],\n",
      "       [5, 4, 3, 8, 9],\n",
      "       [4, 5, 5, 8, 7],\n",
      "       [5, 3, 5, 5, 1],\n",
      "       [7, 0, 3, 1, 3],\n",
      "       [8, 4, 8, 4, 6],\n",
      "       [9, 2, 1, 0, 9],\n",
      "       [8, 4, 8, 4, 4],\n",
      "       [9, 6, 8, 5, 5]])), (6, array([[8, 0, 3, 6, 5],\n",
      "       [6, 4, 3, 2, 2],\n",
      "       [9, 1, 4, 1, 3],\n",
      "       [3, 0, 5, 3, 8],\n",
      "       [7, 1, 3, 4, 1],\n",
      "       [5, 5, 3, 3, 7],\n",
      "       [5, 1, 6, 2, 8],\n",
      "       [2, 2, 1, 3, 8],\n",
      "       [3, 5, 2, 0, 2],\n",
      "       [1, 5, 2, 7, 3]]))]\n",
      "Y: [1 1 1 1 1 1 1 1 1 1]\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "uNum = 10\n",
    "vNum = 10\n",
    "tNum = 10\n",
    "num_instances = 10\n",
    "maxVenue = 5\n",
    "randomeContinuousValue = 100\n",
    "\n",
    "\n",
    "#rec = Recommender(10,10,10,10)\n",
    "\n",
    "\n",
    "users = np.random.randint(uNum, size=(num_instances))\n",
    "times = np.random.randint(uNum, size=(num_instances, maxVenue))\n",
    "time_gaps = np.random.randint(randomeContinuousValue, size=(num_instances, maxVenue, 1))\n",
    "# random distance for visited venues\n",
    "pos_distances = np.random.randint(randomeContinuousValue, size=(num_instances, maxVenue, 1))\n",
    "neg_distances = np.random.randint(randomeContinuousValue, size=(num_instances, maxVenue, 1))\n",
    "checkins = np.random.randint(vNum, size=(num_instances, maxVenue))\n",
    "neg_checkins = np.random.randint(vNum, size=(num_instances, maxVenue))\n",
    "\n",
    "X = [users, times, time_gaps, pos_distances, neg_distances, checkins, neg_checkins]\n",
    "print([x.shape for x in X])\n",
    "print([(i, x) for i, x in enumerate(X)])\n",
    "y = np.array([1]*num_instances)\n",
    "print(\"Y:\", y)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle, choice\n",
    "sequences = []\n",
    "allvenues = set()\n",
    "with open('../../data/ml-1m.txt', 'r') as f:\n",
    "    lastuser = None\n",
    "    for line in f:\n",
    "        line = [int(x) for x in line.split()]\n",
    "        allvenues.add(line[1])\n",
    "        \n",
    "        if lastuser == None:\n",
    "            lastuser = line[0]\n",
    "            seq = (line[0], [])\n",
    "        elif line[0] != lastuser:\n",
    "            sequences.append(seq)\n",
    "            lastuser = line[0]\n",
    "            seq = (line[0], [])\n",
    "        else:\n",
    "            seq[1].append((line[1], line[2]))\n",
    "allvenues = list(allvenues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3416"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allvenues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(16,), (16, 14), (16, 14, 1), (16, 14, 1), (16, 14, 1), (16, 14), (16, 14)] (16,)\n",
      "[(16,), (16, 14), (16, 14, 1), (16, 14, 1), (16, 14, 1), (16, 14), (16, 14)] (16,)\n",
      "[(16,), (16, 14), (16, 14, 1), (16, 14, 1), (16, 14, 1), (16, 14), (16, 14)] (16,)\n",
      "[(16,), (16, 14), (16, 14, 1), (16, 14, 1), (16, 14, 1), (16, 14), (16, 14)] (16,)\n",
      "[(16,), (16, 14), (16, 14, 1), (16, 14, 1), (16, 14, 1), (16, 14), (16, 14)] (16,)\n",
      "[(16,), (16, 14), (16, 14, 1), (16, 14, 1), (16, 14, 1), (16, 14), (16, 14)] (16,)\n",
      "[(16,), (16, 14), (16, 14, 1), (16, 14, 1), (16, 14, 1), (16, 14), (16, 14)] (16,)\n",
      "[(16,), (16, 14), (16, 14, 1), (16, 14, 1), (16, 14, 1), (16, 14), (16, 14)] (16,)\n",
      "[(16,), (16, 14), (16, 14, 1), (16, 14, 1), (16, 14, 1), (16, 14), (16, 14)] (16,)\n",
      "[(16,), (16, 14), (16, 14, 1), (16, 14, 1), (16, 14, 1), (16, 14), (16, 14)] (16,)\n",
      "[(16,), (16, 14), (16, 14, 1), (16, 14, 1), (16, 14, 1), (16, 14), (16, 14)] (16,)\n",
      "[(16,), (16, 14), (16, 14, 1), (16, 14, 1), (16, 14, 1), (16, 14), (16, 14)] (16,)\n",
      "[(16,), (16, 14), (16, 14, 1), (16, 14, 1), (16, 14, 1), (16, 14), (16, 14)] (16,)\n",
      "[(16,), (16, 14), (16, 14, 1), (16, 14, 1), (16, 14, 1), (16, 14), (16, 14)] (16,)\n",
      "[(16,), (16, 14), (16, 14, 1), (16, 14, 1), (16, 14, 1), (16, 14), (16, 14)] (16,)\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: uses global variables from previous cell\n",
    "def batch_generator(batch_size=32, shuffle_every_epoch=True, status=\"train\"):\n",
    "    if status.lower() == 'train':\n",
    "        end = -3\n",
    "    elif status.lower() == 'validate':\n",
    "        end = -2\n",
    "    elif status.lower() == 'test':\n",
    "        end = -1\n",
    "    else:\n",
    "        raise TypeError(\"Status keyword argument must be either 'train', 'test' or 'validate'.\")\n",
    "\n",
    "    if shuffle_every_epoch:\n",
    "        shuffle(sequences)\n",
    "        \n",
    "    min_seq_length = min([len(seq[1]) for seq in sequences])\n",
    "        \n",
    "    batch_pointer = 0\n",
    "    while True:\n",
    "        if batch_pointer + batch_size > len(sequences):\n",
    "            batch_pointer = 0\n",
    "            shuffle(sequences)\n",
    "\n",
    "        batch_seqs = sequences[batch_pointer:batch_pointer+batch_size]\n",
    "        batch_pointer += batch_size\n",
    "        users = np.array([seq[0] for seq in batch_seqs])\n",
    "#        min_seq_length = min([len(seq[1]) for seq in batch_seqs])\n",
    "        times = np.zeros((batch_size, min_seq_length))\n",
    "        time_gaps = np.zeros((batch_size, min_seq_length, 1))\n",
    "        for i, seq in enumerate(batch_seqs):\n",
    "            actual_seq = seq[1]\n",
    "            for j, data in enumerate(actual_seq[:min_seq_length]):\n",
    "                if not j:\n",
    "                    continue\n",
    "                time_gaps[i, j, 0] = data[1] - actual_seq[j-1][1]\n",
    "        pos_distances = np.zeros((batch_size, min_seq_length, 1))\n",
    "        neg_distances = np.zeros((batch_size, min_seq_length, 1))\n",
    "        checkins = np.zeros((batch_size, min_seq_length))\n",
    "        for i, seq in enumerate(batch_seqs):\n",
    "            checkins[i, :] = [x[0] for x in seq[1][:min_seq_length]]\n",
    "        neg_checkins = np.zeros((batch_size, min_seq_length))\n",
    "        for i in range(batch_size):\n",
    "            for j in range(min_seq_length):\n",
    "                while True:\n",
    "                    random_venue = choice(allvenues)\n",
    "                    if random_venue not in neg_checkins[i, :j]:\n",
    "                        break\n",
    "                neg_checkins[i,j] = random_venue\n",
    "        \n",
    "        #chop some of the data off, to leave a target\n",
    "        X = [users, times[:,:end], time_gaps[:,:end], pos_distances[:,:end], neg_distances[:,:end], checkins[:,:end], neg_checkins[:,:end]]\n",
    "        y = checkins[:,end]\n",
    "        yield (X, y)        \n",
    "                \n",
    "data_gen = batch_generator(batch_size = 16)\n",
    "i=0\n",
    "for X,y in data_gen:\n",
    "    i+=1\n",
    "    if i > 15:\n",
    "        break\n",
    "    print([x.shape for x in X], y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1047: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1029: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff9bd5c038d4ca98ca4f9b9ea4507ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=3, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75eb0692221c4601a5dfcb4e53b1ecb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=6039, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 10 values, but the requested shape requires a multiple of 3243\n\t [[node Reshape (defined at /home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1629) ]]\n\t [[node mul_802 (defined at /home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/engine/training.py:672) ]]\n\nCaused by op 'Reshape', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-f37fce91f2f4>\", line 8, in <module>\n    rec = Recommender(num_users, num_items, num_times, latent_dim, seq_length)\n  File \"<ipython-input-2-8a7e916d28f1>\", line 48, in __init__\n    self.u_latent = Flatten()(self.u_embedding(self.user_input))\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/engine/topology.py\", line 572, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/engine/topology.py\", line 635, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/engine/topology.py\", line 166, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/layers/core.py\", line 483, in call\n    return K.batch_flatten(x)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1629, in batch_flatten\n    x = tf.reshape(x, stack([-1, prod(shape(x)[1:])]))\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 7179, in reshape\n    \"Reshape\", tensor=tensor, shape=shape, name=name)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 10 values, but the requested shape requires a multiple of 3243\n\t [[node Reshape (defined at /home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1629) ]]\n\t [[node mul_802 (defined at /home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/engine/training.py:672) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 10 values, but the requested shape requires a multiple of 3243\n\t [[{{node Reshape}}]]\n\t [[{{node mul_802}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f37fce91f2f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m rec.model.fit_generator(batch_generator(batch_size=batch_size), samples_per_epoch=len(sequences)/batch_size, nb_epoch=n_epochs, \n\u001b[0;32m---> 13\u001b[0;31m                        verbose=0, callbacks=[TQDMNotebookCallback()])\n\u001b[0m",
      "\u001b[0;32m~/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1555\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1556\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1557\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1941\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1943\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 10 values, but the requested shape requires a multiple of 3243\n\t [[node Reshape (defined at /home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1629) ]]\n\t [[node mul_802 (defined at /home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/engine/training.py:672) ]]\n\nCaused by op 'Reshape', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-f37fce91f2f4>\", line 8, in <module>\n    rec = Recommender(num_users, num_items, num_times, latent_dim, seq_length)\n  File \"<ipython-input-2-8a7e916d28f1>\", line 48, in __init__\n    self.u_latent = Flatten()(self.u_embedding(self.user_input))\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/engine/topology.py\", line 572, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/engine/topology.py\", line 635, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/engine/topology.py\", line 166, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/layers/core.py\", line 483, in call\n    return K.batch_flatten(x)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1629, in batch_flatten\n    x = tf.reshape(x, stack([-1, prod(shape(x)[1:])]))\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 7179, in reshape\n    \"Reshape\", tensor=tensor, shape=shape, name=name)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 10 values, but the requested shape requires a multiple of 3243\n\t [[node Reshape (defined at /home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1629) ]]\n\t [[node mul_802 (defined at /home/jspijkervet/git/information_retrieval_2/ir2/lib/python3.6/site-packages/keras/engine/training.py:672) ]]\n"
     ]
    }
   ],
   "source": [
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "num_users = len(sequences)\n",
    "num_items = len(allvenues)\n",
    "num_times = 1\n",
    "latent_dim = 10\n",
    "seq_length = 17-3\n",
    "rec = Recommender(num_users, num_items, num_times, latent_dim, seq_length)\n",
    "\n",
    "batch_size = 1\n",
    "n_epochs = 3\n",
    "rec.model.fit_generator(batch_generator(batch_size=batch_size), samples_per_epoch=len(sequences)/batch_size, nb_epoch=n_epochs, \n",
    "                       verbose=0, callbacks=[TQDMNotebookCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec.rank(users, checkins, times, time_gaps, pos_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
