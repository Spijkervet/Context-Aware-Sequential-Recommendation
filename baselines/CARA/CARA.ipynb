{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/adriaan/Documents/ai/ir2/information_retrieval_2/ir2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/adriaan/Documents/ai/ir2/information_retrieval_2/ir2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/adriaan/Documents/ai/ir2/information_retrieval_2/ir2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/adriaan/Documents/ai/ir2/information_retrieval_2/ir2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/adriaan/Documents/ai/ir2/information_retrieval_2/ir2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/adriaan/Documents/ai/ir2/information_retrieval_2/ir2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/adriaan/Documents/ai/ir2/information_retrieval_2/ir2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/adriaan/Documents/ai/ir2/information_retrieval_2/ir2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/adriaan/Documents/ai/ir2/information_retrieval_2/ir2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/adriaan/Documents/ai/ir2/information_retrieval_2/ir2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/adriaan/Documents/ai/ir2/information_retrieval_2/ir2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/adriaan/Documents/ai/ir2/information_retrieval_2/ir2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.engine import InputSpec\n",
    "from keras.layers import Recurrent, initializations, activations, regularizers, time_distributed_dense, SimpleRNN, GRU, \\\n",
    "    LSTM\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "\n",
    "def identity_loss(y_true, y_pred):\n",
    "    return K.mean(y_pred - 0 * y_true)\n",
    "\n",
    "class CARA(GRU):\n",
    "    def __init__(self, output_dim,\n",
    "                 init='glorot_uniform', inner_init='orthogonal',\n",
    "                 activation='tanh', inner_activation='hard_sigmoid',\n",
    "                 W_regularizer=None, U_regularizer=None, b_regularizer=None,\n",
    "                 dropout_W=0., dropout_U=0., **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.init = initializations.get(init)\n",
    "        self.inner_init = initializations.get(inner_init)\n",
    "        self.activation = activations.get(activation)\n",
    "        self.inner_activation = activations.get(inner_activation)\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.U_regularizer = regularizers.get(U_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "        self.dropout_W = dropout_W\n",
    "        self.dropout_U = dropout_U\n",
    "\n",
    "        if self.dropout_W or self.dropout_U:\n",
    "            self.uses_learning_phase = True\n",
    "        super(GRU, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(shape=input_shape)]\n",
    "        self.input_dim = 10\n",
    "\n",
    "        if self.stateful:\n",
    "            self.reset_states()\n",
    "        else:\n",
    "            # initial states: all-zero tensor of shape (output_dim)\n",
    "            self.states = [None]\n",
    "\n",
    "        self.W_z = self.add_weight((self.input_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_W_z'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.U_z = self.add_weight((self.output_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_U_z'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.b_z = self.add_weight((self.output_dim,),\n",
    "                                   initializer='zero',\n",
    "                                   name='{}_b_z'.format(self.name),\n",
    "                                   regularizer=self.b_regularizer)\n",
    "        self.W_r = self.add_weight((self.input_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_W_r'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.U_r = self.add_weight((self.output_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_U_r'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.b_r = self.add_weight((self.output_dim,),\n",
    "                                   initializer='zero',\n",
    "                                   name='{}_b_r'.format(self.name),\n",
    "                                   regularizer=self.b_regularizer)\n",
    "        self.W_h = self.add_weight((self.input_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_W_h'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.U_h = self.add_weight((self.output_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_U_h'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.b_h = self.add_weight((self.output_dim,),\n",
    "                                   initializer='zero',\n",
    "                                   name='{}_b_h'.format(self.name),\n",
    "                                   regularizer=self.b_regularizer)\n",
    "\n",
    "        self.A_h = self.add_weight((self.output_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_A_h'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.A_u = self.add_weight((self.output_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_A_u'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "\n",
    "        self.b_a_h = self.add_weight((self.output_dim,),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b_a_h'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer)\n",
    "        self.b_a_u = self.add_weight((self.output_dim,),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b_a_u'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer)\n",
    "\n",
    "\n",
    "        self.W_t = self.add_weight((self.input_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_W_t'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.U_t = self.add_weight((1, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_U_t'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.b_t = self.add_weight((self.output_dim,),\n",
    "                                   initializer='zero',\n",
    "                                   name='{}_b_t'.format(self.name),\n",
    "                                   regularizer=self.b_regularizer)\n",
    "\n",
    "        self.W_g = self.add_weight((self.input_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_W_g'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.U_g = self.add_weight((1, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_U_g'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.b_g = self.add_weight((self.output_dim,),\n",
    "                                   initializer='zero',\n",
    "                                   name='{}_b_g'.format(self.name),\n",
    "                                   regularizer=self.b_regularizer)\n",
    "\n",
    "\n",
    "\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "\n",
    "    def preprocess_input(self, x):\n",
    "        return x\n",
    "\n",
    "    def step(self, x, states):\n",
    "        h_tm1 = states[0]  # previous memory\n",
    "        B_U = states[1]  # dropout matrices for recurrent units\n",
    "        B_W = states[2]\n",
    "\n",
    "        u = x[:, self.output_dim: 2 * self.output_dim]\n",
    "        t = x[:, 2 * self.output_dim: (2 * self.output_dim) + 1]\n",
    "        g = x[:, (2 * self.output_dim) + 1:]\n",
    "        x = x[:, :self.output_dim]\n",
    "        \n",
    "        t = self.inner_activation(K.dot(t, self.U_t))\n",
    "        g = self.inner_activation(K.dot(g, self.U_g))\n",
    "#       Time-based gate\n",
    "        T = self.inner_activation(K.dot(x, self.W_t) + t + self.b_t)\n",
    "#       Geo-based gate\n",
    "        G = self.inner_activation(K.dot(x, self.W_g) + g + self.b_g)\n",
    "\n",
    "#       Contextual Attention Gate\n",
    "        a = self.inner_activation(\n",
    "            K.dot(h_tm1, self.A_h) + K.dot(u, self.A_u) + self.b_a_h + self.b_a_u)\n",
    "\n",
    "        x_z = K.dot(x, self.W_z) + self.b_z\n",
    "        x_r = K.dot(x, self.W_r) + self.b_r\n",
    "        x_h = K.dot(x, self.W_h) + self.b_h\n",
    "\n",
    "        u_z_ = K.dot((1 - a) * u, self.W_z) + self.b_z\n",
    "        u_r_ = K.dot((1 - a) * u, self.W_r) + self.b_r\n",
    "        u_h_ = K.dot((1 - a) * u, self.W_h) + self.b_h\n",
    "\n",
    "        u_z = K.dot(a * u, self.W_z) + self.b_z\n",
    "        u_r = K.dot(a * u, self.W_r) + self.b_r\n",
    "        u_h = K.dot(a * u, self.W_h) + self.b_h\n",
    "\n",
    "#       update gate\n",
    "        z = self.inner_activation(x_z + K.dot(h_tm1, self.U_z) + u_z)\n",
    "#       reset gate\n",
    "        r = self.inner_activation(x_r + K.dot(h_tm1, self.U_r) + u_r)\n",
    "#       hidden state\n",
    "        hh = self.activation(x_h + K.dot(r * T * G * h_tm1, self.U_h) + u_h)\n",
    "\n",
    "        h = z * h_tm1 + (1 - z) * hh\n",
    "        h = (1 + u_z_ + u_r_ + u_h_) * h\n",
    "        return h, [h]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context-Aware Venue Recommendation with pairwise ranking function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding, Input, merge, SimpleRNN, Activation, Dense, Flatten, GlobalAveragePooling1D, GRU, \\\n",
    "    LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import itertools\n",
    "from keras.regularizers import l2\n",
    "\n",
    "def init_normal(shape, name=None):\n",
    "    return initializations.normal(shape, scale=0.01, name=name)\n",
    "\n",
    "def bpr_triplet_loss(X):\n",
    "    positive_item_latent, negative_item_latent = X\n",
    "\n",
    "    reg = 0\n",
    "\n",
    "    loss = 1 - K.log(K.sigmoid(\n",
    "        K.sum(positive_item_latent, axis=-1, keepdims=True) -\n",
    "        K.sum(negative_item_latent, axis=-1, keepdims=True))) - reg\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Context-Aware Venue Recommendation with pairwise ranking function\n",
    "class Recommender():\n",
    "    def __init__(self, num_users, num_items, num_times, latent_dim, maxVenue):\n",
    "\n",
    "        self.maxVenue = maxVenue\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "#       Inputs\n",
    "        self.user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
    "        self.checkins_input = Input(shape=(self.maxVenue,), dtype='int32', name='venue_input')\n",
    "        self.neg_checkins_input = Input(shape=(self.maxVenue,), dtype='int32', name='neg_venue_input')\n",
    "        self.time_input = Input(shape=(self.maxVenue,), dtype='int32', name='time_input')\n",
    "        self.gap_time_input = Input(shape=(self.maxVenue, 1,), dtype='float32', name='time_interval_input')\n",
    "        \n",
    "        self.u_embedding = Embedding(input_dim=num_users, output_dim=latent_dim, name='user_embedding', \n",
    "                                     init=init_normal)\n",
    "        self.v_embedding = Embedding(input_dim=num_items, output_dim=latent_dim, name='venue_embedding',\n",
    "                                     init=init_normal) \n",
    "        self.t_embedding = Embedding(input_dim=num_times, output_dim=latent_dim, name='time_embedding',\n",
    "                                     init=init_normal) \n",
    "\n",
    "\n",
    "#       User latent factor\n",
    "        self.u_latent = Flatten()(self.u_embedding(self.user_input))\n",
    "        self.t_latent = Flatten()(self.t_embedding(self.time_input))\n",
    "       \n",
    "        rnn_input = merge(\n",
    "                [self.v_embedding(self.checkins_input), self.t_embedding(self.time_input), self.gap_time_input],\n",
    "                mode=\"concat\")\n",
    "        neg_rnn_input = merge(\n",
    "                [self.v_embedding(self.neg_checkins_input), self.t_embedding(self.time_input), self.gap_time_input],\n",
    "                mode=\"concat\")\n",
    "\n",
    "\n",
    "#         rnn_input = self.v_embedding(self.checkins_input)\n",
    "#         neg_rnn_input = self.v_embedding(self.neg_checkins_input)\n",
    "        \n",
    "        \n",
    "        self.pos_distance_input = Input(shape=(self.maxVenue, 1,), dtype='float32', name='pos_distance_input')\n",
    "        self.neg_distance_input = Input(shape=(self.maxVenue, 1,), dtype='float32', name='neg_distance_input')\n",
    "        rnn_input = merge([rnn_input, self.pos_distance_input], mode=\"concat\")\n",
    "        neg_rnn_input = merge([neg_rnn_input, self.neg_distance_input], mode=\"concat\")\n",
    "\n",
    "\n",
    "        self.rnn = Sequential()\n",
    "#       latent_dim * 2 + 2 = v_embedding + t_embedding + time_gap + distance\n",
    "\n",
    "        self.rnn.add(\n",
    "                        CARA(latent_dim, input_shape=(self.maxVenue, (self.latent_dim * 2) + 2,), unroll=True))\n",
    "        \n",
    "\n",
    "        self.checkins_emb = self.rnn(rnn_input)\n",
    "        self.neg_checkins_emb = self.rnn(neg_rnn_input)\n",
    "\n",
    "        pred = merge([self.checkins_emb, self.u_latent], mode=\"dot\")\n",
    "        neg_pred = merge([self.neg_checkins_emb, self.u_latent], mode=\"dot\")\n",
    "\n",
    "        \n",
    "        INPUT = [self.user_input, self.time_input, self.gap_time_input, self.pos_distance_input,\n",
    "                 self.neg_distance_input, self.checkins_input,\n",
    "                 self.neg_checkins_input]\n",
    "\n",
    "        loss = merge([pred, neg_pred], mode=bpr_triplet_loss, name='loss', output_shape=(1,))\n",
    "        self.model = Model(input=INPUT, output=loss)\n",
    "        self.model.compile(optimizer=Adam(), loss=identity_loss)\n",
    "        \n",
    "    \n",
    "\n",
    "    def rank(self, uid, hist_venues, hist_times, hist_time_gap, hist_distances):\n",
    "        \n",
    "#         hist_venues = hist_venues + [candidate_venue]\n",
    "#         hist_times = hist_times + [time]\n",
    "#         hist_time_gap = hist_time_gap + [time_gap]\n",
    "#         hist_distances = hist_distances + [distance]\n",
    "\n",
    "        u_latent = self.model.get_layer('user_embedding').get_weights()[0][uid]\n",
    "        v_latent = self.model.get_layer('venue_embedding').get_weights()[0][hist_venues]\n",
    "        t_latent = self.model.get_layer('time_embedding').get_weights()[0][hist_times]\n",
    "        rnn_input = np.concatenate([t_latent, hist_time_gap], axis=-1)\n",
    "        rnn_input = np.concatenate([rnn_input, hist_distances], axis=-1)\n",
    "\n",
    "        rnn_input = np.concatenate([v_latent, rnn_input], axis=-1)\n",
    "\n",
    "        dynamic_latent = self.rnn.predict(rnn_input)\n",
    "\n",
    "        scores = np.dot(dynamic_latent, u_latent)\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Training Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/adriaan/Documents/ai/ir2/information_retrieval_2/ir2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:321: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/adriaan/Documents/ai/ir2/information_retrieval_2/ir2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:673: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/adriaan/Documents/ai/ir2/information_retrieval_2/ir2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1047: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/adriaan/Documents/ai/ir2/information_retrieval_2/ir2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:634: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/adriaan/Documents/ai/ir2/information_retrieval_2/ir2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:491: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/adriaan/Documents/ai/ir2/information_retrieval_2/ir2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1029: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/adriaan/Documents/ai/ir2/information_retrieval_2/ir2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1237: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/adriaan/Documents/ai/ir2/information_retrieval_2/ir2/lib/python3.7/site-packages/keras/optimizers.py:658: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uNum = 10\n",
    "vNum = 10\n",
    "tNum = 10\n",
    "num_instances = 10\n",
    "maxVenue = 5\n",
    "randomeContinuousValue = 100\n",
    "\n",
    "\n",
    "rec = Recommender(10,10,10,10,5)\n",
    "\n",
    "\n",
    "users = np.random.randint(uNum, size=(num_instances))\n",
    "times = np.random.randint(uNum, size=(num_instances, maxVenue))\n",
    "time_gaps = np.random.randint(randomeContinuousValue, size=(num_instances, maxVenue, 1))\n",
    "# random distance for visited venues\n",
    "pos_distances = np.random.randint(randomeContinuousValue, size=(num_instances, maxVenue, 1))\n",
    "neg_distances = np.random.randint(randomeContinuousValue, size=(num_instances, maxVenue, 1))\n",
    "checkins = np.random.randint(vNum, size=(num_instances, maxVenue))\n",
    "neg_checkins = np.random.randint(vNum, size=(num_instances, maxVenue))\n",
    "\n",
    "X = [users, times, time_gaps, pos_distances, neg_distances, checkins, neg_checkins]\n",
    "y = np.array([1]*num_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle, choice\n",
    "sequences = []\n",
    "allvenues = set()\n",
    "with open('../../data/ml-1m.txt', 'r') as f:\n",
    "    lastuser = None\n",
    "    for line in f:\n",
    "        line = [int(x) for x in line.split()]\n",
    "        allvenues.add(line[1])\n",
    "        \n",
    "        if lastuser == None:\n",
    "            lastuser = line[0]\n",
    "            seq = (line[0], [])\n",
    "        elif line[0] != lastuser:\n",
    "            sequences.append(seq)\n",
    "            lastuser = line[0]\n",
    "            seq = (line[0], [])\n",
    "        else:\n",
    "            seq[1].append((line[1], line[2]))\n",
    "allvenues = list(allvenues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3416"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allvenues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6039\n"
     ]
    }
   ],
   "source": [
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10, 1), (10, 5), (10, 5, 1), (10, 5, 1), (10, 5, 1), (10, 5), (10, 5)]\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: uses global variables from previous cell\n",
    "max_seq_len = 30\n",
    "def batch_generator(batch_size=32, shuffle_every_epoch=True, status=\"train\"):\n",
    "    if status.lower() == 'train':\n",
    "        end = -3\n",
    "    elif status.lower() == 'validate':\n",
    "        end = -2\n",
    "    elif status.lower() == 'test':\n",
    "        end = -1\n",
    "    else:\n",
    "        raise TypeError(\"Status keyword argument must be either 'train', 'test' or 'validate'.\")\n",
    "\n",
    "    if shuffle_every_epoch:\n",
    "        shuffle(sequences)\n",
    "                \n",
    "    batch_pointer = 0\n",
    "    while True:\n",
    "        if batch_pointer + batch_size > len(sequences):\n",
    "            batch_pointer = 0\n",
    "            shuffle(sequences)\n",
    "\n",
    "        batch_seqs = sequences[batch_pointer:batch_pointer+batch_size]\n",
    "        batch_pointer += batch_size\n",
    "\n",
    "        users = np.array([seq[0] for seq in batch_seqs])\n",
    "        times = np.zeros((batch_size, max_seq_len))\n",
    "        time_gaps = np.zeros((batch_size, max_seq_len, 1))\n",
    "        for i, seq in enumerate(batch_seqs):\n",
    "            actual_seq = seq[1]\n",
    "            to_pad = len(actual_seq[:max_seq_len]) - max_seq_len\n",
    "            for j, data in enumerate(actual_seq[:max_seq_len]):                \n",
    "                if not j:\n",
    "                    continue\n",
    "                time_gaps[i, j+to_pad, 0] = data[1] - actual_seq[j-1][1]\n",
    "\n",
    "        pos_distances = np.zeros((batch_size, max_seq_len, 1))\n",
    "        neg_distances = np.zeros((batch_size, max_seq_len, 1))\n",
    "        \n",
    "    \n",
    "        checkins = np.zeros((batch_size, max_seq_len))\n",
    "        for i, seq in enumerate(batch_seqs):\n",
    "            seq_len = len(seq[1])\n",
    "            to_pad = max_seq_len - seq_len\n",
    "            if to_pad < 0:\n",
    "                to_pad = 0\n",
    "            checkins[i, to_pad:] = [x[0] for x in seq[1][:max_seq_len]]\n",
    "       \n",
    "        \n",
    "        neg_checkins = np.zeros((batch_size, max_seq_len))\n",
    "        for i in range(batch_size):\n",
    "            for j in range(max_seq_len):\n",
    "                while True:\n",
    "                    random_venue = choice(allvenues)\n",
    "                    if random_venue not in neg_checkins[i, :j]:\n",
    "                        break\n",
    "                neg_checkins[i,j] = random_venue\n",
    "        \n",
    "        #chop some of the data off, to leave a target\n",
    "        X = [users, times[:,3+end:end], time_gaps[:,3+end:end], pos_distances[:,3+end:end], neg_distances[:,3+end:end], checkins[:,3+end:end], neg_checkins[:,3+end:end]]\n",
    "        y = checkins[:,end]\n",
    "        yield (X, y)        \n",
    "         \n",
    "def data_as_array(shuffle_every_epoch=True, status='train'):\n",
    "    full_batch_size=len(sequences)\n",
    "    gen = batch_generator(full_batch_size, shuffle_every_epoch, status)\n",
    "    return next(gen)\n",
    "\n",
    "\n",
    "our_X, our_y = data_as_array()\n",
    "print([x.shape for x in X])\n",
    "print(y.shape)\n",
    "num_users = len(sequences)+1  #+1 for 1-indexed things\n",
    "num_items = len(allvenues)+1\n",
    "num_times = 1\n",
    "latent_dim = 10\n",
    "seq_length = max_seq_len-3\n",
    "print('building model')\n",
    "our_rec = Recommender(num_users, num_items, num_times, latent_dim, seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fit\n",
      "Epoch 1/10\n",
      "6039/6039 [==============================] - 12s - loss: nan    \n",
      "Epoch 2/10\n",
      "6039/6039 [==============================] - 12s - loss: nan    \n",
      "Epoch 3/10\n",
      "6039/6039 [==============================] - 2582s - loss: nan  \n",
      "Epoch 4/10\n",
      "6039/6039 [==============================] - 14s - loss: nan    \n",
      "Epoch 5/10\n",
      "6039/6039 [==============================] - 14s - loss: nan    \n",
      "Epoch 6/10\n",
      "6039/6039 [==============================] - 14s - loss: nan    \n",
      "Epoch 7/10\n",
      "6039/6039 [==============================] - 14s - loss: nan    \n",
      "Epoch 8/10\n",
      "6039/6039 [==============================] - 14s - loss: nan    \n",
      "Epoch 9/10\n",
      "6039/6039 [==============================] - 14s - loss: nan    \n",
      "Epoch 10/10\n",
      "6039/6039 [==============================] - 14s - loss: nan    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f07e06db908>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('starting fit')\n",
    "our_rec.model.fit(our_X, our_y)\n",
    "\n",
    "#batch_size = 1\n",
    "#n_epochs = 3\n",
    "#rec.model.fit_generator(batch_generator(batch_size=batch_size), samples_per_epoch=len(sequences)/batch_size, nb_epoch=n_epochs, \n",
    "#                       verbose=0, callbacks=[TQDMNotebookCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.1281504e-03,  4.9669396e-02,  4.7867853e-02,  5.3519651e-02,\n",
       "         4.5163287e-03, -4.3194063e-02,  2.8528353e-02, -1.3919793e-02,\n",
       "        -1.1167181e-02, -9.1847070e-03],\n",
       "       [ 1.0511249e-02,  3.0926164e-02,  2.4137642e-02,  3.5139296e-02,\n",
       "         8.6953817e-03, -2.4211656e-02,  6.7943656e-03,  5.0942291e-04,\n",
       "        -1.7230593e-02, -8.0384444e-03],\n",
       "       [-3.4712396e-06,  2.6446545e-02,  2.9189633e-02,  2.8373191e-02,\n",
       "        -2.0828142e-03, -2.8288838e-02,  1.2782577e-02, -1.0945490e-02,\n",
       "        -7.9965489e-03, -2.0975890e-03],\n",
       "       [ 6.2142657e-03,  4.9183335e-02,  4.8247728e-02,  5.3336322e-02,\n",
       "         3.3441363e-03, -4.3575574e-02,  3.0040627e-02, -1.6577171e-02,\n",
       "        -9.9017629e-03, -9.3925679e-03],\n",
       "       [-4.1438662e-03,  2.3647267e-02,  3.2718144e-02,  2.6225621e-02,\n",
       "        -7.3303645e-03, -3.3317361e-02,  6.9555021e-03, -1.2746973e-02,\n",
       "        -1.1009975e-02,  3.0773520e-03],\n",
       "       [ 1.8072218e-02,  5.0914634e-02,  3.3704259e-02,  5.2417949e-02,\n",
       "         1.7086055e-02, -2.7732596e-02,  3.7289608e-02, -7.2976826e-03,\n",
       "        -5.2829599e-03, -2.2556121e-02],\n",
       "       [-9.9636242e-04,  1.7476862e-02,  2.2567373e-02,  1.8315947e-02,\n",
       "        -1.0434244e-03, -2.3033334e-02,  9.1769882e-03, -6.8237088e-03,\n",
       "        -6.4946455e-03, -3.0832030e-03],\n",
       "       [ 2.7917197e-03,  2.3246828e-02,  2.4474820e-02,  2.7973849e-02,\n",
       "         1.2685644e-03, -2.6411442e-02, -1.2178466e-03, -2.1042547e-03,\n",
       "        -1.8603215e-02, -5.4395461e-04],\n",
       "       [ 7.6486510e-03,  3.9489202e-02,  3.3132050e-02,  4.1158281e-02,\n",
       "         6.4305156e-03, -2.9211959e-02,  2.6075648e-02, -1.0352134e-02,\n",
       "        -5.9639043e-03, -1.1064272e-02],\n",
       "       [-1.1464551e-03,  1.7490832e-02,  2.2680679e-02,  1.7726120e-02,\n",
       "        -2.7883020e-03, -2.4170173e-02,  7.3661981e-03, -7.7920365e-03,\n",
       "        -7.5635999e-03, -2.4953666e-03]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec.rank(users, checkins, times, time_gaps, pos_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "venue_input (InputLayer)         (None, 5)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "time_input (InputLayer)          (None, 5)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "neg_venue_input (InputLayer)     (None, 5)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "venue_embedding (Embedding)      (None, 5, 10)         100         venue_input[0][0]                \n",
      "                                                                   neg_venue_input[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "time_embedding (Embedding)       (None, 5, 10)         100         time_input[0][0]                 \n",
      "                                                                   time_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "time_interval_input (InputLayer) (None, 5, 1)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 5, 21)         0           venue_embedding[0][0]            \n",
      "                                                                   time_embedding[1][0]             \n",
      "                                                                   time_interval_input[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "pos_distance_input (InputLayer)  (None, 5, 1)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "user_input (InputLayer)          (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 5, 21)         0           venue_embedding[1][0]            \n",
      "                                                                   time_embedding[2][0]             \n",
      "                                                                   time_interval_input[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "neg_distance_input (InputLayer)  (None, 5, 1)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_3 (Merge)                  (None, 5, 22)         0           merge_1[0][0]                    \n",
      "                                                                   pos_distance_input[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "user_embedding (Embedding)       (None, 1, 10)         100         user_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "merge_4 (Merge)                  (None, 5, 22)         0           merge_2[0][0]                    \n",
      "                                                                   neg_distance_input[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)        (None, 10)            1090        merge_3[0][0]                    \n",
      "                                                                   merge_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 10)            0           user_embedding[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "merge_5 (Merge)                  (None, 1)             0           sequential_1[1][0]               \n",
      "                                                                   flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_6 (Merge)                  (None, 1)             0           sequential_1[2][0]               \n",
      "                                                                   flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "loss (Merge)                     (None, 1)             0           merge_5[0][0]                    \n",
      "                                                                   merge_6[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 1,390\n",
      "Trainable params: 1,390\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(rec.model.summary())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "ir2",
   "language": "python",
   "name": "ir2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
